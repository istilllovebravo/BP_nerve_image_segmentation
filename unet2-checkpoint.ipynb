{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b642e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    " from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imsave\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Conv2DTranspose,Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.activations import softmax\n",
    " \n",
    " \n",
    " \n",
    " \n",
    "K.set_image_data_format('channels_last')  # TF dimension ordering in this code\n",
    " \n",
    "img_rows = 96\n",
    "img_cols = 96\n",
    " \n",
    "smooth = 1.\n",
    " \n",
    " \n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    \n",
    " \n",
    " \n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    " \n",
    " \n",
    "def get_unet():\n",
    "    inputs = Input((img_rows, img_cols, 1))\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++++++++new Line\")\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    " \n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    " \n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    " \n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    print(tf.shape(conv4))\n",
    "    #split\n",
    "    td=conv4\n",
    "    \n",
    "    tx=softmax(td,axis=[1,2])\n",
    "    q=1.5\n",
    "    \n",
    "    \n",
    "    \n",
    "    safe_x = K.maximum(tx,1e-6)\n",
    "    new_p = K.switch(K.equal(q,1.), K.log(safe_x),(K.pow(safe_x,q))/(q-1))\n",
    "    new_p = -new_p #-p^q/(q-1)\n",
    " \n",
    " \n",
    "    new_p= 1+new_p\n",
    "    print(\"new_p\",new_p.shape)\n",
    "    xyz=K.max(new_p,axis=[1,2],keepdims=True)\n",
    "    print(\"xyz=\",xyz.shape)\n",
    "   \n",
    "    \n",
    "    print(\"xyz=\",xyz.shape)\n",
    "    weights=1-(new_p/xyz)\n",
    "    print(\"weights\",weights.shape)\n",
    "    improved_p=td*weights\n",
    "    print(\"improved_p=\",improved_p.shape)\n",
    "    improved_p=K.sum(improved_p,axis=[1,2])/144\n",
    "    print(\"improved_pv2=\",type(improved_p),improved_p.shape)\n",
    "    \n",
    "#     n=tx.shape[0]\n",
    "#     temp=tf.zeros([0,0],tf.float32)\n",
    "    \n",
    "#     for i in range(n):\n",
    "#         print(\"=========inside loop\",i)\n",
    "#         safe_x = K.maximum(tx[i],1e-6)\n",
    "#         new_p = K.switch(K.equal(q,1.), K.log(safe_x),(K.pow(safe_x,q))/(q-1))\n",
    "#         new_p = -new_p #-p^q/(q-1)\n",
    "    \n",
    "    \n",
    "#         new_p= 1+new_p\n",
    "#         weights=1-(new_p/K.max(new_p))\n",
    "    \n",
    "#         improved_p=td[i]*weights\n",
    "        \n",
    "#         temp=tf.concat([temp,(K.sum(improved_p)/144)],0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     dense_nodes=K.reshape(K.variable(temp),shape=(1,256))\n",
    "#     print(dense_nodes.shape)\n",
    "    ####\n",
    "#     den=[]\n",
    "#     for i in range(n):\n",
    "#         den.append(tf.reduce_sum(before_gap[i])/144)\n",
    "    \n",
    "    \n",
    "#     dense_nodes=tf.Variable(den)\n",
    "#     dense_nodes=tf.reshape(dense_nodes,shape=(1,256))\n",
    "    \n",
    "#     dense_nodes=K.sum(before_gap,axis=1)/144.0\n",
    "#     print(dense_nodes.shape)\n",
    "#     dense_nodes=K.reshape(before_gap,shape=(1,256))\n",
    "    \n",
    "    \n",
    "#     print(\"temp type=\",type(temp[0]))\n",
    "#     dense_nodes = tf. convert_to_tensor(improved_p)\n",
    "#     print(\"dense node=\",dense_nodes)\n",
    "#     xy=tf.reshape(dense_nodes,(1,256))\n",
    "#     print(\"xy=\",xy)\n",
    "    #improved_p=tf.reshape(improved_p,(1,256))\n",
    "    dense1=Dense(32,activation='relu')(improved_p)\n",
    "    print(\"dense1\",dense1)\n",
    "    dense2=Dense(1,activation='softmax')(dense1)\n",
    "    print(\"below dense\",dense2)\n",
    "    \n",
    "    \n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "    \n",
    "    print(\"conv5=\",conv5)\n",
    " \n",
    "    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    " \n",
    "    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    " \n",
    "    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    " \n",
    "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    " \n",
    "    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "    print(\"conv10=\", conv10) \n",
    " \n",
    "    model = Model(inputs=[inputs], outputs=[conv10,dense2])\n",
    " \n",
    "    model.compile(optimizer=Adam(lr=1e-5), loss=[dice_coef_loss,\n",
    "                                                 tf.keras.losses.BinaryCrossentropy()],\n",
    "                  metrics=[dice_coef,tf.keras.metrics.BinaryCrossentropy()])\n",
    " \n",
    "    return model\n",
    " \n",
    " \n",
    "def preprocess(imgs):\n",
    "    imgs_p = np.ndarray((imgs.shape[0], img_rows, img_cols), dtype=np.uint8)\n",
    "    for i in range(imgs.shape[0]):\n",
    "        imgs_p[i] = resize(imgs[i], (img_cols, img_rows), preserve_range=True)\n",
    " \n",
    "    imgs_p = imgs_p[..., np.newaxis]\n",
    "    return imgs_p\n",
    " \n",
    " \n",
    "def train_and_predict():\n",
    "    imgs_train,imgs_mask_train,imgs_value_train=load_train_data()\n",
    " \n",
    "    imgs_train = preprocess(imgs_train)\n",
    "    imgs_mask_train = preprocess(imgs_mask_train)\n",
    " \n",
    "    imgs_train = imgs_train.astype('float32')\n",
    "    mean = np.mean(imgs_train)  # mean for data centering\n",
    "    std = np.std(imgs_train)  # std for data normalization\n",
    " \n",
    "    imgs_train -= mean\n",
    "    imgs_train /= std\n",
    " \n",
    "    imgs_mask_train = imgs_mask_train.astype('float32')\n",
    "    imgs_mask_train /= 255.  # scale masks to [0, 1]\n",
    " \n",
    "    print('-'*30)\n",
    "    print('Creating and compiling model...')\n",
    "    print('-'*30)\n",
    "    model = get_unet()\n",
    "    model_checkpoint = ModelCheckpoint('weights.h5', monitor='val_loss' , mode = 'min' , verbose = 1 , save_best_only=True )\n",
    " \n",
    "    print('-'*30)\n",
    "    print('Fitting model...')\n",
    "    print('-'*30)\n",
    "    model.fit(imgs_train, y=[imgs_mask_train,imgs_value_train], batch_size=32, epochs= 20, verbose=1, shuffle=True,\n",
    "              validation_split=0.2 ,  callbacks=[model_checkpoint])\n",
    "    \n",
    "    print('-'*30)\n",
    "    print('Loading and preprocessing test data...')\n",
    "    print('-'*30)\n",
    "    imgs_test, imgs_id_test = load_test_data()\n",
    "    imgs_test = preprocess(imgs_test)\n",
    "\n",
    "    imgs_test = imgs_test.astype('float32')\n",
    "    imgs_test -= mean\n",
    "    imgs_test /= std\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Loading saved weights...')\n",
    "    print('-'*30)\n",
    "    model.load_weights('weights.h5')\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Predicting masks on test data...')\n",
    "    print('-'*30)\n",
    "    n_imgs_test = imgs_test.shape[0]\n",
    "    #for i in range(n_imgs_test):\n",
    "\n",
    "    #worked for 7 vs 1\n",
    "    #imgs_mask_test, imgs_value_test= model.predict(np.expand_dims(imgs_test[0] , axis = 0), verbose=1)\n",
    "\n",
    "\n",
    "    imgs_mask_test, imgs_value_test= model.predict(imgs_test, verbose=1)\n",
    "    print(\"mask final img 1\" , imgs_mask_test)\n",
    "    np.save('imgs_mask_test.npy', imgs_mask_test)\n",
    "\n",
    "    print('-' * 30)\n",
    "    print('Saving predicted masks to files...')\n",
    "    print('-' * 30)\n",
    "    pred_dir = 'preds'\n",
    "    if not os.path.exists(pred_dir):\n",
    "        os.mkdir(pred_dir)\n",
    "    for image, image_id in zip(imgs_mask_test, imgs_id_test):\n",
    "        image = (image[:, :, 0] * 255.).astype(np.uint8)\n",
    "        imsave(os.path.join(pred_dir, str(image_id) + '_pred.png'), image)\n",
    "\n",
    "\n",
    " \n",
    "     \n",
    "if __name__ == '__main__':\n",
    "    train_and_predict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
